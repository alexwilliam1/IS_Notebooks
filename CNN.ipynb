{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construindo a Arquitetura da CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras import utils\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Aquisição dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'C://Users//alexw//Documents//UFPI//Sistemas_Inteligentes//21-06-10_CNN//animals//'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_name_class(image_path):\n",
    "    image = image_path.split('\\\\')[-1]\n",
    "    image_name = re.sub(r'\\.jpg', \"\", image)\n",
    "    \n",
    "    class_name = image_path.split('\\\\')[-2]\n",
    "    \n",
    "    return image_name, class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(dataset_path):\n",
    "    #Captura os nomes das pastas\n",
    "    name_folders = glob.glob(dataset_path + '*')\n",
    "    cats_labels, cats_images = [],[] # armazena as imagens e os labels da classe gatos\n",
    "    dogs_labels, dogs_images = [],[] # armazena as imagens e os labels da classe dogs\n",
    "    panda_labels, panda_images = [],[] # armazena as imagens e os labels da classe panda\n",
    "    \n",
    "    for names_ in name_folders:\n",
    "        #Captura o caminho completo da imagem\n",
    "        path_images = glob.glob(names_ + '\\\\*.jpg')\n",
    "        class_ = names_.split('\\\\')[-1]\n",
    "        \n",
    "        for i,path_ in enumerate(tqdm(path_images, desc=class_)):\n",
    "            image_name, label = get_images_name_class(path_)\n",
    "            image = load_img(path_, \n",
    "                             color_mode='rgb', \n",
    "                             target_size=(64,64), \n",
    "                             interpolation='nearest') # Carerga a imagem em formato RGB, com resolução 64x64\n",
    "            \n",
    "            if label == \"cats\":\n",
    "                cats_labels.append(label)\n",
    "                img_arr = img_to_array(image)\n",
    "                cats_images.append(img_arr)\n",
    "                \n",
    "            elif label == \"dogs\":\n",
    "                dogs_labels.append(label)\n",
    "                img_arr = img_to_array(image)\n",
    "                dogs_images.append(img_arr)\n",
    "                \n",
    "            elif label == \"panda\":\n",
    "                panda_labels.append(label)\n",
    "                img_arr = img_to_array(image)\n",
    "                panda_images.append(img_arr) \n",
    "  \n",
    "    # divide classe cats em 80% treino e 20% teste com embaralhamaento ativado\n",
    "    cats_xtrain, cats_xtest, cats_ytrain, cats_ytest = train_test_split(cats_images, \n",
    "                                                                          cats_labels, \n",
    "                                                                          train_size=0.8, \n",
    "                                                                          shuffle=True) \n",
    "    # divide classe dogs em 80% treino e 20% teste com embaralhamaento ativado\n",
    "    dogs_xtrain, dogs_xtest, dogs_ytrain, dogs_ytest = train_test_split(dogs_images, \n",
    "                                                                          dogs_labels, \n",
    "                                                                          train_size=0.8, \n",
    "                                                                          shuffle=True) \n",
    "    # divide classe panda em 80% treino e 20% teste com embaralhamaento ativado\n",
    "    panda_xtrain, panda_xtest, panda_ytrain, panda_ytest = train_test_split(panda_images, \n",
    "                                                                               panda_labels, \n",
    "                                                                               train_size=0.8, \n",
    "                                                                               shuffle=True) \n",
    "    \n",
    "    # unifica e converte para numpy array os x_train, x_test, y_train e y_test que foram divididos por classe\n",
    "    x_tr = np.array(cats_xtrain + dogs_xtrain + panda_xtrain)\n",
    "    x_te = np.array(cats_xtest + dogs_xtest + panda_xtest)\n",
    "    y_tr = np.array(cats_ytrain + dogs_ytrain + panda_ytrain)\n",
    "    y_te = np.array(cats_ytest + dogs_ytest + panda_ytest)\n",
    "    \n",
    "    return x_tr, x_te, y_tr, y_te\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cats: 100%|█████████████████████████████████████████████████████████████| 1000/1000 [00:04<00:00, 227.23it/s]\n",
      "dogs: 100%|█████████████████████████████████████████████████████████████| 1000/1000 [00:05<00:00, 193.66it/s]\n",
      "panda: 100%|█████████████████████████████████████████████████████████████| 1000/1000 [00:11<00:00, 90.08it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = run(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 64, 64, 3)\n",
      "(2400,)\n",
      "(600, 64, 64, 3)\n",
      "(600,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 3)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 3)\n",
    "\n",
    "y_train = LabelEncoder().fit_transform(y_train)\n",
    "y_train = utils.to_categorical(y_train)\n",
    "y_test = LabelEncoder().fit_transform(y_test)\n",
    "y_test = utils.to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 64, 64, 3)\n",
      "(2400, 3)\n",
      "(600, 64, 64, 3)\n",
      "(600, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Arquitetura da CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicializando a CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "#Camada de convolução\n",
    "classifier.add(Convolution2D(32, kernel_size=(5,5), input_shape = (64, 64,3), activation = 'relu', padding='same', name = 'conv_1'))\n",
    "\n",
    "#Camada de pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2), padding='same', name = 'pool_1'))\n",
    "\n",
    "#Segunda camada convolucional\n",
    "classifier.add(Convolution2D(32, kernel_size=(5,5), activation = 'relu', padding='same', name = 'conv_2'))\n",
    "\n",
    "#Camada de pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2), padding='same', name = 'pool_2'))\n",
    "\n",
    "#Segunda camada convolucional\n",
    "classifier.add(Convolution2D(64, kernel_size=(5,5), activation = 'relu', padding='same', name = 'conv_3'))\n",
    "\n",
    "#Dropout\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    "#Segunda camada de pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name = 'pool_3'))\n",
    "\n",
    "#Vetorizando os mapas de características do último pooling (camada de entrada)\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#Dropout\n",
    "classifier.add(Dropout(0.5))\n",
    "\n",
    "#Camada totalmente conectada ou oculta\n",
    "classifier.add(Dense(activation='relu', units=128, name = 'dense_1'))\n",
    "\n",
    "\n",
    "#Camada de saída\n",
    "classifier.add(Dense(activation='softmax', units=3,  name = 'classification'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              (None, 64, 64, 32)        2432      \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling2D)        (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 32, 32, 32)        25632     \n",
      "_________________________________________________________________\n",
      "pool_2 (MaxPooling2D)        (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 16, 16, 64)        51264     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "pool_3 (MaxPooling2D)        (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "classification (Dense)       (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 604,131\n",
      "Trainable params: 604,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parâmetros de treinamento\n",
    "epochs = 40\n",
    "batch_size = 40\n",
    "validation_split=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adamax', loss= 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('best_model.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto', save_freq='epoch') \n",
    "earlystop = keras.callbacks.EarlyStopping(patience=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "54/54 [==============================] - 18s 319ms/step - loss: 1.0706 - accuracy: 0.4134 - val_loss: 0.9831 - val_accuracy: 0.6458\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.98308, saving model to best_model.h5\n",
      "Epoch 2/40\n",
      "54/54 [==============================] - 18s 333ms/step - loss: 0.8305 - accuracy: 0.5653 - val_loss: 0.4109 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.98308 to 0.41093, saving model to best_model.h5\n",
      "Epoch 3/40\n",
      "54/54 [==============================] - 20s 370ms/step - loss: 0.7558 - accuracy: 0.6027 - val_loss: 0.5451 - val_accuracy: 0.8292\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.41093\n",
      "Epoch 4/40\n",
      "54/54 [==============================] - 19s 357ms/step - loss: 0.7196 - accuracy: 0.6174 - val_loss: 1.0333 - val_accuracy: 0.6167\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.41093\n",
      "Epoch 5/40\n",
      "54/54 [==============================] - 21s 381ms/step - loss: 0.7115 - accuracy: 0.6371 - val_loss: 0.4795 - val_accuracy: 0.8458\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.41093\n",
      "Epoch 6/40\n",
      "54/54 [==============================] - 21s 387ms/step - loss: 0.6672 - accuracy: 0.6851 - val_loss: 0.5017 - val_accuracy: 0.8208\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.41093\n",
      "Epoch 7/40\n",
      "54/54 [==============================] - 21s 395ms/step - loss: 0.6451 - accuracy: 0.6736 - val_loss: 0.4583 - val_accuracy: 0.8375\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.41093\n",
      "Epoch 8/40\n",
      "54/54 [==============================] - 20s 373ms/step - loss: 0.6337 - accuracy: 0.6657 - val_loss: 0.4017 - val_accuracy: 0.8625\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.41093 to 0.40166, saving model to best_model.h5\n",
      "Epoch 9/40\n",
      "54/54 [==============================] - 20s 362ms/step - loss: 0.6071 - accuracy: 0.7189 - val_loss: 0.3066 - val_accuracy: 0.8875\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.40166 to 0.30664, saving model to best_model.h5\n",
      "Epoch 10/40\n",
      "54/54 [==============================] - 20s 370ms/step - loss: 0.5978 - accuracy: 0.7164 - val_loss: 0.1971 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.30664 to 0.19709, saving model to best_model.h5\n",
      "Epoch 11/40\n",
      "54/54 [==============================] - 19s 345ms/step - loss: 0.5805 - accuracy: 0.7095 - val_loss: 0.5339 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.19709\n",
      "Epoch 12/40\n",
      "54/54 [==============================] - 18s 342ms/step - loss: 0.5620 - accuracy: 0.7330 - val_loss: 0.1734 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.19709 to 0.17339, saving model to best_model.h5\n",
      "Epoch 13/40\n",
      "54/54 [==============================] - 18s 326ms/step - loss: 0.5374 - accuracy: 0.7448 - val_loss: 0.2081 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.17339\n",
      "Epoch 14/40\n",
      "54/54 [==============================] - 19s 351ms/step - loss: 0.5348 - accuracy: 0.7648 - val_loss: 0.1934 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.17339\n",
      "Epoch 15/40\n",
      "54/54 [==============================] - 18s 341ms/step - loss: 0.5054 - accuracy: 0.7472 - val_loss: 0.1678 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.17339 to 0.16778, saving model to best_model.h5\n",
      "Epoch 16/40\n",
      "54/54 [==============================] - 18s 337ms/step - loss: 0.5082 - accuracy: 0.7567 - val_loss: 0.4144 - val_accuracy: 0.8417\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.16778\n",
      "Epoch 17/40\n",
      "54/54 [==============================] - 20s 375ms/step - loss: 0.4614 - accuracy: 0.8027 - val_loss: 0.3442 - val_accuracy: 0.8833\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.16778\n",
      "Epoch 18/40\n",
      "54/54 [==============================] - 20s 364ms/step - loss: 0.4404 - accuracy: 0.7938 - val_loss: 0.1664 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.16778 to 0.16643, saving model to best_model.h5\n",
      "Epoch 19/40\n",
      "54/54 [==============================] - 20s 370ms/step - loss: 0.4567 - accuracy: 0.7934 - val_loss: 0.4863 - val_accuracy: 0.8125\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.16643\n",
      "Epoch 20/40\n",
      "54/54 [==============================] - 21s 384ms/step - loss: 0.4466 - accuracy: 0.8060 - val_loss: 0.7116 - val_accuracy: 0.7458\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.16643\n",
      "Epoch 21/40\n",
      "54/54 [==============================] - 20s 367ms/step - loss: 0.4838 - accuracy: 0.7843 - val_loss: 0.2648 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.16643\n",
      "Epoch 22/40\n",
      "54/54 [==============================] - 19s 355ms/step - loss: 0.3733 - accuracy: 0.8399 - val_loss: 0.3217 - val_accuracy: 0.8833\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.16643\n",
      "Epoch 23/40\n",
      "54/54 [==============================] - 21s 387ms/step - loss: 0.3937 - accuracy: 0.8164 - val_loss: 0.2092 - val_accuracy: 0.9083\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.16643\n",
      "Epoch 24/40\n",
      "54/54 [==============================] - 19s 346ms/step - loss: 0.3701 - accuracy: 0.8387 - val_loss: 0.2963 - val_accuracy: 0.8917\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.16643\n",
      "Epoch 25/40\n",
      "54/54 [==============================] - 18s 330ms/step - loss: 0.3490 - accuracy: 0.8510 - val_loss: 0.1982 - val_accuracy: 0.9250\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.16643\n",
      "Epoch 26/40\n",
      "54/54 [==============================] - 19s 347ms/step - loss: 0.3981 - accuracy: 0.8230 - val_loss: 0.2614 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.16643\n",
      "Epoch 27/40\n",
      "54/54 [==============================] - 20s 367ms/step - loss: 0.3143 - accuracy: 0.8590 - val_loss: 0.3287 - val_accuracy: 0.8917\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.16643\n",
      "Epoch 28/40\n",
      "54/54 [==============================] - 19s 357ms/step - loss: 0.3195 - accuracy: 0.8700 - val_loss: 0.3584 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.16643\n",
      "Epoch 29/40\n",
      "54/54 [==============================] - 21s 385ms/step - loss: 0.2994 - accuracy: 0.8792 - val_loss: 0.1946 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.16643\n",
      "Epoch 30/40\n",
      "54/54 [==============================] - 19s 354ms/step - loss: 0.2912 - accuracy: 0.8800 - val_loss: 0.2789 - val_accuracy: 0.8917\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.16643\n",
      "Epoch 31/40\n",
      "54/54 [==============================] - 19s 361ms/step - loss: 0.2764 - accuracy: 0.8854 - val_loss: 0.2144 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.16643\n",
      "Epoch 32/40\n",
      "54/54 [==============================] - 19s 361ms/step - loss: 0.2615 - accuracy: 0.8937 - val_loss: 0.2023 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.16643\n",
      "Epoch 33/40\n",
      "54/54 [==============================] - 18s 333ms/step - loss: 0.2544 - accuracy: 0.8908 - val_loss: 0.2292 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.16643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b893c49130>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x_train, y_train, validation_split=validation_split, batch_size=batch_size, epochs=epochs, callbacks=[checkpoint,earlystop], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Avaliando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melhor wesultado item 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_1 = keras.models.load_model(\"75_best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5844899415969849\n",
      "Test accuracy: 0.9283333420753479\n"
     ]
    }
   ],
   "source": [
    "score1 = best_model_1.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score1[0])\n",
    "print(\"Test accuracy:\", score1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melhor resultado item 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model2 = keras.models.load_model(\"77_2_best_model.h5\") # ITEM 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3047352731227875\n",
      "Test accuracy: 0.9383333325386047\n"
     ]
    }
   ],
   "source": [
    "score2 = best_model2.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score2[0])\n",
    "print(\"Test accuracy:\", score2[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
